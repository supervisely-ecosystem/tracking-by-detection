{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b364026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "from yolox.data.data_augment import preproc\n",
    "from yolox.exp import get_exp\n",
    "from yolox.utils import fuse_model, get_model_info, postprocess\n",
    "from yolox.utils.visualize import plot_tracking\n",
    "\n",
    "from tracker.mc_bot_sort import BoTSORT\n",
    "from tracker.tracking_utils.timer import Timer\n",
    "\n",
    "\n",
    "\n",
    "exp = get_exp('../yolox/exps/example/mot/yolox_s_mix_det.py', 'yolox_s_mix_det')\n",
    "\n",
    "model = exp.get_model().to('cpu')\n",
    "model.eval()\n",
    "\n",
    "ckpt_file = '../../yolox_s_coco.pth'\n",
    "ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n",
    "\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "msg = model.load_state_dict(ckpt[\"model\"])\n",
    "model.eval()\n",
    "print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63622a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    appearance_thresh=0.25,\n",
    "    camid=0,\n",
    "    ckpt='../../yolox_s_coco.pt',\n",
    "    cmc_method='sparseOptFlow',\n",
    "    conf=0.1,\n",
    "    demo='images',\n",
    "    device='cpu',\n",
    "    exp_file='../yolox/exps/example/mot/yolox_s_mix_det.py',\n",
    "    experiment_name=None,\n",
    "    fast_reid_config='../fast_reid/configs/MOT17/sbs_S50.yml',\n",
    "    fast_reid_weights='../pretrained/mot17_sbs_S50.pth',\n",
    "    fp16=False,\n",
    "    fps=30,\n",
    "    fuse=False,\n",
    "    fuse_score=False,\n",
    "    match_thresh=0.8,\n",
    "    min_box_area=10,\n",
    "    name=None,\n",
    "    new_track_thresh=0.1,\n",
    "    nms=None,\n",
    "    path='../../data/images',\n",
    "    proximity_thresh=0.5,\n",
    "    save_result=True,\n",
    "    track_buffer=30,\n",
    "    track_high_thresh=0.3,\n",
    "    track_low_thresh=0.1,\n",
    "    trt=False,\n",
    "    tsize=None,\n",
    "    with_reid=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8acf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_EXT = [\".jpg\", \".jpeg\", \".webp\", \".bmp\", \".png\"]\n",
    "\n",
    "def get_image_list(path):\n",
    "    image_names = []\n",
    "    for maindir, subdir, file_name_list in os.walk(path):\n",
    "        for filename in file_name_list:\n",
    "            apath = osp.join(maindir, filename)\n",
    "            ext = osp.splitext(apath)[1]\n",
    "            if ext in IMAGE_EXT:\n",
    "                image_names.append(apath)\n",
    "    return image_names\n",
    "\n",
    "args.ablation = False\n",
    "args.mot20 = None\n",
    "\n",
    "files = get_image_list(args.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9feb53c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        exp,\n",
    "        trt_file=None,\n",
    "        decoder=None,\n",
    "        device=torch.device(\"cpu\"),\n",
    "        fp16=False\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.decoder = decoder\n",
    "        self.num_classes = exp.num_classes\n",
    "        self.confthre = exp.test_conf\n",
    "        self.nmsthre = exp.nmsthre\n",
    "        self.test_size = exp.test_size\n",
    "        self.device = device\n",
    "        self.fp16 = fp16\n",
    "        if trt_file is not None:\n",
    "            from torch2trt import TRTModule\n",
    "\n",
    "            model_trt = TRTModule()\n",
    "            model_trt.load_state_dict(torch.load(trt_file))\n",
    "\n",
    "            x = torch.ones((1, 3, exp.test_size[0], exp.test_size[1]), device=device)\n",
    "            self.model(x)\n",
    "            self.model = model_trt\n",
    "        self.rgb_means = (0.485, 0.456, 0.406)\n",
    "        self.std = (0.229, 0.224, 0.225)\n",
    "\n",
    "    def inference(self, img, timer):\n",
    "        img_info = {\"id\": 0}\n",
    "        if isinstance(img, str):\n",
    "            img_info[\"file_name\"] = osp.basename(img)\n",
    "            img = cv2.imread(img)\n",
    "        else:\n",
    "            img_info[\"file_name\"] = None\n",
    "\n",
    "        height, width = img.shape[:2]\n",
    "        img_info[\"height\"] = height\n",
    "        img_info[\"width\"] = width\n",
    "        img_info[\"raw_img\"] = img\n",
    "\n",
    "        img, ratio = preproc(img, self.test_size, self.rgb_means, self.std)\n",
    "        img_info[\"ratio\"] = ratio\n",
    "        img = torch.from_numpy(img).unsqueeze(0).float().to(self.device)\n",
    "        if self.fp16:\n",
    "            img = img.half()  # to FP16\n",
    "\n",
    "        with torch.no_grad():\n",
    "            timer.tic()\n",
    "            outputs = self.model(img)\n",
    "            if self.decoder is not None:\n",
    "                outputs = self.decoder(outputs, dtype=outputs.type())\n",
    "            outputs = postprocess(outputs, self.num_classes, self.confthre, self.nmsthre)\n",
    "        return outputs, img_info\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c273e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-18 00:54:28.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[1mArgs: Namespace(ablation=False, appearance_thresh=0.25, camid=0, ckpt='../../yolox_s_coco.pt', cmc_method='sparseOptFlow', conf=0.1, demo='images', device='cpu', exp_file='../yolox/exps/example/mot/yolox_s_mix_det.py', experiment_name=None, fast_reid_config='../fast_reid/configs/MOT17/sbs_S50.yml', fast_reid_weights='../pretrained/mot17_sbs_S50.pth', fp16=False, fps=30, fuse=False, fuse_score=False, match_thresh=0.8, min_box_area=10, mot20=True, name=None, new_track_thresh=0.1, nms=None, path='../../data/images', proximity_thresh=0.5, save_result=True, track_buffer=30, track_high_thresh=0.3, track_low_thresh=0.1, trt=False, tsize=None, with_reid=False)\u001b[0m\n",
      "c:\\Users\\79504\\Desktop\\Projects\\venv38\\lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\u001b[32m2025-06-18 00:54:28.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mModel Summary: Params: 8.97M, Gflops: 75.73\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "exp = get_exp(args.exp_file, args.name)\n",
    "\n",
    "args.ablation = False\n",
    "args.mot20 = not args.fuse_score\n",
    "\n",
    "logger.info(\"Args: {}\".format(args))\n",
    "\n",
    "if args.conf is not None:\n",
    "    exp.test_conf = args.conf\n",
    "if args.nms is not None:\n",
    "    exp.nmsthre = args.nms\n",
    "if args.tsize is not None:\n",
    "    exp.test_size = (args.tsize, args.tsize)\n",
    "    \n",
    "logger.info(\"Model Summary: {}\".format(get_model_info(model, exp.test_size)))\n",
    "\n",
    "trt_file = None\n",
    "decoder = None\n",
    "\n",
    "predictor = Predictor(model, exp, trt_file, decoder, args.device, args.fp16)\n",
    "\n",
    "tracker = BoTSORT(args, frame_rate=args.fps)\n",
    "\n",
    "timer = Timer()\n",
    "results = []\n",
    "\n",
    "for frame_id, img_path in enumerate(files, 1):\n",
    "\n",
    "    # Detect objects\n",
    "    outputs, img_info = predictor.inference(img_path, timer)\n",
    "    scale = min(exp.test_size[0] / float(img_info['height'], ), exp.test_size[1] / float(img_info['width']))\n",
    "\n",
    "    detections = []\n",
    "    if outputs[0] is not None:\n",
    "        outputs = outputs[0].cpu().numpy()\n",
    "        detections = outputs[:, :7]\n",
    "        detections[:, :4] /= scale\n",
    "\n",
    "    # Run tracker\n",
    "    online_targets = tracker.update(detections, img_info['raw_img'])\n",
    "\n",
    "    online_tlwhs = []\n",
    "    online_ids = []\n",
    "    online_scores = []\n",
    "    online_cls = []\n",
    "    for t in online_targets:\n",
    "        tlwh = t.tlwh\n",
    "        tid = t.track_id\n",
    "        if tlwh[2] * tlwh[3] > args.min_box_area:\n",
    "            online_tlwhs.append(tlwh)\n",
    "            online_ids.append(tid)\n",
    "            online_scores.append(t.score)\n",
    "            online_cls.append(t.cls)\n",
    "\n",
    "            # save results\n",
    "            results.append(\n",
    "                f\"{frame_id},{tid},{tlwh[0]:.2f},{tlwh[1]:.2f},{tlwh[2]:.2f},{tlwh[3]:.2f},{t.score:.2f},-1,-1,-1\\n\"\n",
    "            )\n",
    "    timer.toc()\n",
    "    online_im = plot_tracking(\n",
    "        img_info['raw_img'], online_tlwhs, online_ids, frame_id=frame_id, fps=1. / timer.average_time, ids2=online_cls\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "094f2728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,219.68,336.83,154.47,60.42,0.41,-1,-1,-1\\n',\n",
       " '2,1,209.27,333.38,122.37,63.71,0.30,-1,-1,-1\\n',\n",
       " '3,1,182.76,333.56,166.75,72.42,0.45,-1,-1,-1\\n',\n",
       " '4,1,136.28,332.62,200.91,85.17,0.39,-1,-1,-1\\n',\n",
       " '5,1,77.34,336.88,230.28,92.84,0.16,-1,-1,-1\\n',\n",
       " '108,2,931.95,254.14,102.46,282.72,0.43,-1,-1,-1\\n',\n",
       " '109,3,1002.96,234.87,127.26,312.55,0.84,-1,-1,-1\\n',\n",
       " '157,4,1121.56,293.82,132.95,96.26,0.32,-1,-1,-1\\n',\n",
       " '170,5,764.01,301.94,97.01,54.41,0.37,-1,-1,-1\\n',\n",
       " '171,5,776.93,301.64,106.23,60.07,0.45,-1,-1,-1\\n',\n",
       " '172,5,790.11,301.58,117.38,61.40,0.42,-1,-1,-1\\n',\n",
       " '173,5,821.90,298.03,110.61,64.03,0.19,-1,-1,-1\\n',\n",
       " '174,5,824.19,296.88,132.19,69.57,0.18,-1,-1,-1\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
